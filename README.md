# リアルタイムOCRアプリケーション

macOS上で動作するリアルタイムOCRシステムです。指定されたウィンドウ（iPhoneシミュレータやミラーリングアプリ）をキャプチャし、YOLOv8で小説リスト項目を検出、Tesseract OCRで日本語テキストを抽出し、CSV形式で保存します。

## 機能概要

- **リアルタイムウィンドウキャプチャ**: 指定したウィンドウを継続的にキャプチャ
- **YOLOv8物体検出**: 学習済みモデルでリスト項目を検出
  - **標準モード**: list-item全体を1つの領域として検出
  - **階層的検出モード**: list-item内部の詳細要素（タイトル、進捗、最終読書日時、サイト名）を個別に検出
- **日本語OCR**: Tesseract OCRで日本語テキストを抽出
- **重複排除**: 自動的に重複データを除外（曖昧マッチング対応）
- **CSV出力**: 抽出データをCSV形式で保存
- **リアルタイムプレビュー**: 検出結果を視覚的に確認
- **セッション管理**: 検出された画像を自動保存・ZIP圧縮

## システム要件

- **OS**: macOS 11.0 (Big Sur) 以降
- **CPU**: Apple Silicon (M1/M2/M3) または Intel
- **Python**: 3.9 以降
- **Tesseract OCR**: 4.0 以降

## インストール手順

### 1. Homebrewのインストール（未インストールの場合）

```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

### 2. Tesseract OCRのインストール

```bash
brew install tesseract tesseract-lang
```

日本語言語データが含まれていることを確認:

```bash
tesseract --list-langs
```

出力に`jpn`が含まれていればOKです。

### 3. Python仮想環境の作成（推奨）

プロジェクト専用の仮想環境を作成することで、システムのPython環境に影響を与えずに依存関係を管理できます。

```bash
# 仮想環境を作成
python3 -m venv venv

# 仮想環境を有効化
source venv/bin/activate

# 仮想環境を無効化する場合（終了時）
deactivate
```

**注意**: 仮想環境は`.gitignore`に含まれており、Gitリポジトリには追加されません。

### 4. 依存関係のインストール

仮想環境を有効化した状態で、以下のコマンドを実行してください:

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 5. YOLOv8モデルの配置

学習済みYOLOv8モデル（`best.pt`）を以下のパスに配置してください:

```
models/best.pt
```

または、設定ファイルでモデルパスを指定できます。

## macOS権限設定

このアプリケーションは画面をキャプチャするため、macOSの**画面収録権限**が必要です。

### 権限の付与手順

1. **システム環境設定**を開く
2. **セキュリティとプライバシー**を選択
3. **プライバシー**タブをクリック
4. 左側のリストから**画面収録**を選択
5. 鍵アイコンをクリックして変更を許可
6. **ターミナル**（またはPythonを実行するアプリ）にチェックを入れる
7. アプリケーションを再起動

### 権限が付与されていない場合

初回実行時に権限を求めるダイアログが表示されます。権限を付与後、アプリケーションを再起動してください。

## 階層的検出機能

### 概要

階層的検出機能は、list-item内部の詳細要素を個別に検出し、構造化されたデータとして出力する機能です。約1700作品のデータを別アプリへ移行する際に、より詳細な情報を抽出できます。

### 検出クラス

階層的検出モデルは、以下の5つのクラスを検出します:

1. **list-item**: リスト項目全体の領域（親要素）
2. **title**: 作品タイトル（子要素）
3. **progress**: 読書進捗（例: 38/768）（子要素・オプション）
4. **last_read_date**: 最終読書日時（例: 4週間前）（子要素）
5. **site_name**: サイト名（例: カクヨム、小説家になろう）（子要素）

### 親子関係の判定

- モデルは5つのクラスをフラットに検出します
- 推論後、プログラム側でIoU（Intersection over Union）計算により親子関係を構築します
- 各子要素は、最も重なりが大きいlist-itemに紐付けられます
- 孤立した子要素（どのlist-itemにも含まれない）は警告ログに記録されます

### 出力形式

階層的検出モードでは、以下の列を持つCSVファイルを出力します:

```csv
list_item_id,title,progress,last_read_date,site_name,image_path,error_status
list_item_001,転生したらスライムだった件,38/768,4週間前,カクヨム,sessions/20251016_143022/list_item_001.jpg,OK
list_item_002,無職転生,120/250,,小説家になろう,sessions/20251016_143022/list_item_002.jpg,missing_last_read_date
```

- **list_item_id**: 一意の識別子
- **title**: 作品タイトル（OCR抽出）
- **progress**: 読書進捗（OCR抽出・オプション）
- **last_read_date**: 最終読書日時（OCR抽出）
- **site_name**: サイト名（OCR抽出）
- **image_path**: 切り出された画像の相対パス
- **error_status**: エラーステータス（"OK"または欠損項目のリスト）

### セッション管理

階層的検出モードでは、検出されたlist-item領域を自動的に画像として保存します:

1. **セッション開始**: 処理開始時にタイムスタンプ付きフォルダを作成（例: `output/sessions/20251016_143022/`）
2. **画像保存**: 各list-itemの領域をマージン付きで切り出し、連番ファイル名で保存（例: `list_item_001.jpg`）
3. **ZIP圧縮**: 処理終了時にセッションフォルダをZIPファイルに圧縮
4. **Finderで開く**: GUIから「画像フォルダを開く」ボタンでセッションフォルダを確認可能

### 曖昧マッチングによる重複排除

階層的検出モードでは、OCRの誤認識を考慮した曖昧マッチングで重複を排除します:

- **文字列類似度**: `difflib.SequenceMatcher`を使用してタイトルの類似度を計算
- **しきい値**: デフォルト0.75（GUIで調整可能: 0.6〜0.9）
- **重複判定**: 類似度がしきい値以上の場合、重複と判定してスキップ
- **ログ出力**: 重複検出時、類似度と既存タイトルをターミナルに表示

例:
```
🔄 重複検出: '転生したらスライムだつた件' ≈ '転生したらスライムだった件' (類似度: 0.97)
```

### エラーハンドリング

階層的検出モードでは、以下のエラーを適切に処理します:

- **必須項目の欠損**: title、last_read_date、site_nameが検出されない場合、error_status列に記録
- **孤立した子要素**: どのlist-itemにも紐付けられない子要素は警告ログに出力
- **OCRエラー**: OCR処理失敗時は空文字列を返して処理を継続
- **画像保存エラー**: 画像保存失敗時はエラーログに記録して処理を継続

### 学習データセットの準備

階層的検出モデルを学習するには、以下の手順でデータセットを準備します:

#### 1. アノテーション形式

YOLO形式（各画像に対応する`.txt`ファイル）でアノテーションを作成します:

```
# Format: <class_id> <x_center> <y_center> <width> <height> (normalized 0-1)

# Example: IMG_1307.txt
0 0.501062 0.248689 0.997876 0.080154  # list-item
1 0.250000 0.230000 0.450000 0.030000  # title
2 0.850000 0.250000 0.120000 0.020000  # progress
3 0.250000 0.270000 0.200000 0.020000  # last_read_date
4 0.750000 0.270000 0.150000 0.020000  # site_name
```

#### 2. クラスラベルの定義

`data.yaml`ファイルでクラスラベルを定義します:

```yaml
# data.yaml
path: temp/shosetsu-list-item_dataset_v2
train: obj_train_data
val: obj_train_data

nc: 5

names:
  0: list-item
  1: title
  2: progress
  3: last_read_date
  4: site_name
```

#### 3. ディレクトリ構造

```
temp/shosetsu-list-item_dataset_v2/
├── data.yaml
├── obj.data
├── obj.names
└── obj_train_data/
    ├── IMG_1307.png
    ├── IMG_1307.txt
    ├── IMG_1308.png
    ├── IMG_1308.txt
    └── ...
```

#### 4. モデルの学習

学習スクリプトを実行してモデルをトレーニングします:

```bash
# 仮想環境をアクティベート
source venv/bin/activate

# 学習スクリプトを実行
python scripts/train_hierarchical_model.py
```

学習完了後、以下のファイルが生成されます:
- `models/hierarchical-detection/weights/best.pt`: ベストモデル
- `models/hierarchical_best.pt`: ベストモデルのコピー（アプリケーションで使用）
- `models/hierarchical-detection/results.csv`: 学習結果の精度指標
- `models/hierarchical-detection/results.png`: 学習曲線
- `models/hierarchical-detection/confusion_matrix.png`: 混同行列

詳細は「学習スクリプトのドキュメント」セクションを参照してください。

## 使用方法

### GUIモード（推奨）

グラフィカルユーザーインターフェースを使用して、視覚的に操作できます。

```bash
# 仮想環境をアクティベート（作成した場合）
source venv/bin/activate

# GUIモードで起動
python src/gui_app.py
```

**GUIの機能**:
- **設定パネル**: ウィンドウタイトル、信頼度しきい値、OCR言語、出力パスなどを設定
  - **モデル選択**: 標準モデル（list-item全体）または階層的モデル（5クラス）を選択
  - **類似度しきい値**: 階層的モードでの重複判定の類似度しきい値を調整（0.6〜0.9）
- **制御パネル**: 
  - **ウィンドウ選択とプレビュー**: ウィンドウを選択して即座にプレビュー表示を開始
  - **開始/停止**: 物体検知とOCR処理の開始/停止（プレビューは継続）
  - **一時停止/再開**: 処理を一時停止/再開（プレビューは継続）
  - **CSV出力**: いつでもデータをCSVに出力
  - **画像フォルダを開く**: 階層的モードで保存された画像フォルダをFinderで開く
- **リアルタイムプレビュー**: キャプチャされた画面をリアルタイムで表示
  - プレビューモード: キャプチャのみ（物体検知なし）
  - 処理モード: キャプチャ + 物体検知 + OCR（緑色の矩形で検出結果を表示）
  - 階層的モード: 5クラスのbounding boxを異なる色で描画
- **データログ**: 抽出されたテキストをリアルタイムで表示（新規/重複を色分け）
- **統計情報**: 抽出件数、処理フレーム数、検出数、実行時間を表示
  - 階層的モード: 各クラスの検出数、エラー件数、正常件数を個別に表示

**GUIの使い方**:
1. **ウィンドウを選択**: ドロップダウンから対象ウィンドウを選択（または手動入力）
2. **プレビュー開始**: 「ウィンドウを選択してプレビュー」ボタンをクリック
3. **処理開始**: プレビューが表示されたら「開始」ボタンをクリックして物体検知とOCRを開始
4. **一時停止**: 必要に応じて「一時停止」ボタンで処理を一時停止（プレビューは継続）
5. **停止**: 「停止」ボタンで処理を停止（プレビューは継続）
6. **プレビュー停止**: 「プレビューを停止」ボタンですべてを停止

**ステータス表示**:
- **停止中** (黒色): すべての処理が停止
- **プレビュー中** (青色): キャプチャのみ実行中
- **処理中** (緑色): キャプチャ + 物体検知 + OCR実行中
- **一時停止中** (オレンジ色): 処理が一時停止（プレビューは継続）

### CLIモード（コマンドライン）

従来のコマンドラインインターフェースでも実行できます。

```bash
# 仮想環境をアクティベート（作成した場合）
source venv/bin/activate

# CLIモードで実行
python src/realtime_ocr_app.py
```

### 設定のカスタマイズ

`src/config.py`で以下の設定を変更できます:

- **model_path**: YOLOv8モデルファイルのパス
- **target_window_title**: キャプチャ対象のウィンドウタイトル（部分一致）
- **confidence_threshold**: 検出の信頼度しきい値（0.0-1.0）
- **output_csv**: 出力CSVファイル名
- **ocr_lang**: OCR言語（デフォルト: `jpn`）

### 終了方法

**GUIモード**:
- **停止ボタン**: GUIの「停止」ボタンをクリック
- **ウィンドウを閉じる**: GUIウィンドウの閉じるボタン（×）をクリック
- **CSV出力ボタン**: 実行中でも「CSV出力」ボタンでいつでも保存可能

**CLIモード**:
- **'q'キー**: プレビューウィンドウで'q'キーを押すと終了
- **Ctrl+C**: ターミナルでCtrl+Cを押すと安全に終了

終了時に抽出されたデータが自動的にCSVファイルに保存されます。

## パフォーマンス最適化

このアプリケーションは、マルチスレッド処理とキャッシング機構により、高速なリアルタイムOCR処理を実現しています。

### パフォーマンスアーキテクチャ

アプリケーションは以下の並列処理パイプラインで動作します:

```
[キャプチャスレッド] → [検出スレッド] → [OCRワーカープール] → [表示スレッド]
        ↓                    ↓                    ↓
   フレームキュー        検出結果キュー        表示キュー
```

**主要な最適化技術**:
- **マルチスレッド処理**: キャプチャ、物体検出、OCR処理を並列実行
- **検出結果キャッシュ**: 類似フレームで物体検出をスキップ
- **OCR結果キャッシュ**: 同じ領域のOCR結果を再利用
- **並列OCR処理**: 複数の検出領域を同時にOCR処理
- **フレームスキップ**: 処理が追いつかない場合、古いフレームを破棄

### パフォーマンスモード

GUIモードでは、用途に応じて3つのパフォーマンスモードを選択できます:

#### 🚀 高速モード (Fast)
- **FPS目標**: 10-15 FPS
- **用途**: リアルタイム性を最優先する場合
- **特徴**:
  - 2フレームに1回処理（フレームスキップ有効）
  - 検出キャッシュとOCRキャッシュを積極的に使用
  - OCRワーカー数: 4
  - 最大検出数: 5件/フレーム
- **推奨環境**: Apple Silicon (M1/M2/M3)

#### ⚖️ バランスモード (Balanced) - デフォルト
- **FPS目標**: 5-10 FPS
- **用途**: 精度とパフォーマンスのバランスを取る場合
- **特徴**:
  - 全フレーム処理
  - 検出キャッシュとOCRキャッシュを使用
  - OCRワーカー数: 3
  - 最大検出数: 10件/フレーム
- **推奨環境**: すべての環境

#### 🎯 高精度モード (Accurate)
- **FPS目標**: 3-5 FPS
- **用途**: 精度を最優先する場合
- **特徴**:
  - 全フレーム処理
  - キャッシュを無効化（毎回検出とOCRを実行）
  - OCRワーカー数: 2
  - 最大検出数: 20件/フレーム
- **推奨環境**: 高性能なマシン

### パフォーマンスモードの選択方法

**GUIモード**:
1. GUIの設定パネルで「パフォーマンスモード」ドロップダウンを選択
2. 希望のモード（高速/バランス/高精度）を選択
3. 処理を開始すると、選択したモードで動作

**設定ファイル**:
`src/config.py`の`AppConfig`で以下を設定:
```python
performance_mode: str = "balanced"  # "fast", "balanced", "accurate"
```

### 期待されるパフォーマンス

| 環境 | 高速モード | バランスモード | 高精度モード |
|------|-----------|--------------|-------------|
| **Apple Silicon (M3 Pro)** | 12-15 FPS | 8-10 FPS | 4-6 FPS |
| **Apple Silicon (M1/M2)** | 10-12 FPS | 6-8 FPS | 3-5 FPS |
| **Intel Mac** | 8-10 FPS | 5-7 FPS | 2-4 FPS |

**注意**: 実際のFPSは以下の要因により変動します:
- ウィンドウサイズ（大きいほど処理時間が増加）
- 検出される項目数（多いほど処理時間が増加）
- 他のアプリケーションの負荷
- OCR言語データの複雑さ

### パフォーマンス統計の確認

GUIモードでは、リアルタイムでパフォーマンス統計を確認できます:

- **FPS**: 現在のフレームレート
- **処理フレーム数**: 処理されたフレームの総数
- **検出数**: 検出された項目の総数
- **実行時間**: 処理開始からの経過時間

### パフォーマンスチューニング

パフォーマンスをさらに向上させるためのヒント:

1. **信頼度しきい値を上げる**: 検出数を減らして処理を高速化
   ```python
   confidence_threshold: float = 0.7  # デフォルト: 0.6
   ```

2. **ウィンドウサイズを小さくする**: キャプチャ解像度を下げて処理を高速化

3. **不要なアプリケーションを閉じる**: CPUとメモリリソースを確保

4. **Apple Silicon環境でMPSを有効化**: YOLOv8がMetal Performance Shadersを使用
   ```python
   # 自動的に検出されますが、明示的に指定も可能
   device: str = "mps"  # Apple Silicon
   ```

5. **キャッシュTTLを調整**: キャッシュの有効期間を調整
   ```python
   # src/pipeline_processor.py
   self.detection_cache = DetectionCache(ttl=0.5)  # 秒単位
   ```

### トラブルシューティング: パフォーマンス

#### FPSが目標値に達しない

**原因と対策**:

1. **検出数が多すぎる**
   - 信頼度しきい値を上げる（0.7-0.8）
   - 高速モードに切り替える

2. **ウィンドウサイズが大きすぎる**
   - ウィンドウを小さくする
   - または、キャプチャ領域を制限する

3. **他のアプリケーションの負荷**
   - 不要なアプリケーションを閉じる
   - アクティビティモニタでCPU使用率を確認

4. **キャッシュが効いていない**
   - 画面が頻繁に変化している場合、キャッシュヒット率が低下
   - バランスモードまたは高速モードを試す

#### メモリ使用量が多い

**対策**:
- 最大検出数を制限する
- キャッシュTTLを短くする
- 高精度モードから他のモードに切り替える

#### 処理が遅延する

**対策**:
- フレームキューのサイズを調整（デフォルト: 2）
- OCRワーカー数を減らす（メモリ使用量とのトレードオフ）
- 高速モードに切り替える

## プロジェクト構造

```
.
├── src/                    # ソースコード
│   ├── gui_app.py          # GUIアプリケーション（推奨）
│   ├── realtime_ocr_app.py # CLIアプリケーション
│   ├── window_capture.py   # ウィンドウキャプチャモジュール
│   ├── object_detector.py  # YOLOv8物体検出モジュール
│   ├── hierarchical_detector.py # 階層的検出モジュール
│   ├── iou_calculator.py   # IoU計算モジュール
│   ├── ocr_processor.py    # OCRモジュール
│   ├── hierarchical_ocr_processor.py # 階層的OCR処理モジュール
│   ├── data_manager.py     # データ管理モジュール
│   ├── hierarchical_data_manager.py # 階層的データ管理モジュール
│   ├── session_manager.py  # セッション管理モジュール
│   ├── hierarchical_pipeline.py # 階層的パイプライン処理モジュール
│   ├── visualizer.py       # 可視化モジュール
│   ├── error_handler.py    # エラーハンドリングモジュール
│   ├── pipeline_processor.py # パイプライン処理モジュール
│   ├── performance_monitor.py # パフォーマンス計測モジュール
│   ├── detection_cache.py  # 検出結果キャッシュモジュール
│   ├── ocr_cache.py        # OCR結果キャッシュモジュール
│   ├── performance_mode.py # パフォーマンスモード設定
│   └── config.py           # 設定管理
├── config/                 # 設定ファイル（オプション）
│   └── config.example.yaml # サンプル設定ファイル
├── models/                 # YOLOv8モデルファイル
│   ├── best.pt            # 学習済みモデル（標準）
│   ├── hierarchical_best.pt # 学習済みモデル（階層的検出）
│   └── hierarchical-detection/ # 階層的モデルの学習結果
│       ├── weights/
│       │   ├── best.pt
│       │   └── last.pt
│       ├── results.csv
│       ├── results.png
│       └── confusion_matrix.png
├── output/                 # 出力ファイル
│   ├── book_data_realtime.csv # 標準モードの出力
│   ├── hierarchical_data.csv  # 階層的モードの出力
│   └── sessions/          # セッション画像フォルダ（階層的モード）
│       ├── 20251016_143022/
│       │   ├── list_item_001.jpg
│       │   └── ...
│       └── 20251016_143022.zip
├── temp/                   # 一時ファイル・学習データ
│   └── shosetsu-list-item_dataset_v2/ # 階層的検出用データセット
│       ├── data.yaml
│       └── obj_train_data/
│           ├── IMG_1307.png
│           ├── IMG_1307.txt
│           └── ...
├── tests/                  # テストコード
│   ├── test_hierarchical_detector.py
│   ├── test_hierarchical_data_manager.py
│   ├── test_hierarchical_integration.py
│   ├── test_gui_hierarchical.py
│   └── ...
├── scripts/                # スクリプト
│   ├── train_hierarchical_model.py # 階層的モデル学習
│   ├── train_yolov8.py    # 既存モデル学習
│   └── debug/             # デバッグスクリプト
├── docs/                   # ドキュメント
│   ├── DEVELOPMENT.md     # 開発ガイド
│   ├── gui_testing_guide.md
│   ├── integration_test_results.md
│   └── implementation_notes/ # 実装メモ
├── requirements.txt        # Python依存関係
└── README.md              # このファイル
```

## トラブルシューティング

### ウィンドウが見つからない

**エラー**: `Error: Window not found`

**解決策**:
1. ターゲットウィンドウが開いていることを確認
2. ウィンドウタイトルが正しいか確認（部分一致で検索されます）
3. 利用可能なウィンドウリストを確認して、正しいタイトルを指定

### Tesseractが見つからない

**エラー**: `TesseractNotFoundError`

**解決策**:
```bash
brew install tesseract tesseract-lang
```

インストール後、Tesseractのパスを確認:
```bash
which tesseract
```

### 画面収録権限エラー

**エラー**: 画面がキャプチャできない

**解決策**:
1. システム環境設定 > セキュリティとプライバシー > プライバシー > 画面収録
2. ターミナル（またはPythonアプリ）に権限を付与
3. アプリケーションを再起動

### モデルファイルが見つからない

**エラー**: `Model file not found`

**解決策**:
1. `best.pt`ファイルが`models/`ディレクトリに存在することを確認
2. または、`src/config.py`で正しいパスを指定

### OCR精度が低い

**対策**:
1. ウィンドウのサイズを大きくする
2. 画面の解像度を上げる
3. `ocr_margin`パラメータを調整（デフォルト: 5ピクセル）
4. 画像前処理を有効化（`OCRProcessor.preprocess_image()`）

### パフォーマンスが遅い

**対策**:
1. **パフォーマンスモードを変更**: GUIで「高速モード」に切り替える
2. `confidence_threshold`を上げて検出数を減らす（0.7-0.8推奨）
3. Apple Silicon環境でMPS（Metal Performance Shaders）が有効か確認
4. 不要なアプリケーションを閉じてリソースを確保
5. ウィンドウサイズを小さくする

詳細は「パフォーマンス最適化」セクションを参照してください。

### GUIが起動しない

**エラー**: `ModuleNotFoundError: No module named 'tkinter'`

**解決策**:
macOSの場合、Pythonに標準でtkinterが含まれていますが、Homebrewでインストールしたpython3の場合は以下を実行:
```bash
brew install python-tk@3.9  # または使用しているPythonバージョン
```

### データが重複して保存される

**問題**: 同じデータが複数回CSVに保存される

**解決策**:
- アプリケーションは自動的に重複を排除します
- GUIのデータログで重複データはグレー表示されます
- 既存のCSVファイルに追記する場合は、手動で重複を削除してください

## 学習スクリプトのドキュメント

### scripts/train_hierarchical_model.py

階層的検出用の5クラスモデルを学習するスクリプトです。

#### 使用方法

```bash
# 仮想環境をアクティベート
source venv/bin/activate

# 学習スクリプトを実行
python scripts/train_hierarchical_model.py
```

#### データ拡張パラメータ

少量データ（9〜10枚）での過学習を防ぐため、以下のデータ拡張を適用します:

| パラメータ | 値 | 説明 |
|-----------|-----|------|
| **hsv_h** | 0.02 | 色相の変動（やや増加） |
| **hsv_s** | 0.8 | 彩度の変動（増加） |
| **hsv_v** | 0.5 | 明度の変動（増加） |
| **degrees** | 15 | 回転角度（増加） |
| **translate** | 0.15 | 平行移動（増加） |
| **scale** | 0.6 | スケール変動（増加） |
| **mosaic** | 1.0 | モザイク拡張（有効） |
| **mixup** | 0.0 | Mixup拡張（無効化・安定性のため） |
| **copy_paste** | 0.0 | Copy-Paste拡張（無効化・安定性のため） |
| **flipud** | 0.0 | 上下反転（無効・テキストには不適切） |
| **fliplr** | 0.0 | 左右反転（無効・テキストには不適切） |

**注意事項**:
- 上下・左右反転は、テキストの向きを保持するため無効化しています
- MixupとCopy-Pasteは、学習の安定性のため無効化しています
- これらのパラメータは、データセットの特性に応じて調整可能です

#### 学習設定

| 設定項目 | 値 | 説明 |
|---------|-----|------|
| **エポック数** | 100 | 学習の反復回数 |
| **画像サイズ** | 1280 | 入力画像のサイズ（元画像のアスペクト比を考慮） |
| **バッチサイズ** | 4 | 画像サイズが大きいため小さめに設定 |
| **Early stopping patience** | 20 | 精度が改善しない場合の早期停止 |
| **デバイス** | mps/cuda/cpu | 自動検出（Apple Silicon優先） |

#### 学習結果の確認

学習完了後、以下のファイルで結果を確認できます:

1. **学習曲線**: `models/hierarchical-detection/results.png`
   - 各エポックでの損失、精度、mAPの推移を確認

2. **混同行列**: `models/hierarchical-detection/confusion_matrix.png`
   - 各クラスの検出精度と誤検出を確認

3. **精度指標**: `models/hierarchical-detection/results.csv`
   - mAP50、mAP50-95、Precision、Recallなどの詳細な指標

4. **学習ログ**: ターミナル出力
   - 各エポックの進捗と最終結果を確認

#### 精度指標の見方

- **mAP50**: IoU=0.5での平均精度（一般的な指標）
- **mAP50-95**: IoU=0.5〜0.95での平均精度（より厳密な指標）
- **Precision**: 検出結果のうち正解の割合（誤検出の少なさ）
- **Recall**: 正解のうち検出できた割合（見逃しの少なさ）

#### トラブルシューティング

**過学習の兆候がある場合**:
- データ拡張パラメータをさらに強化（hsv_v、degrees、translateを増加）
- エポック数を減らす
- Early stopping patienceを小さくする

**精度が低い場合**:
- アノテーションを見直す（特にbounding boxの精度）
- エポック数を増やす
- 学習データを追加する
- 信頼度しきい値を調整する

**学習が不安定な場合**:
- バッチサイズを小さくする（2に変更）
- 学習率を下げる（`lr0=0.001`を追加）
- データ拡張を弱める（各パラメータを半分に）

## 開発情報

### 開発環境のセットアップ

開発時は必ず仮想環境を使用してください:

```bash
# 仮想環境を作成（初回のみ）
python3 -m venv venv

# 仮想環境を有効化
source venv/bin/activate

# 依存関係をインストール
pip install -r requirements.txt
```

### テストの実行

仮想環境を有効化した状態でテストを実行:

```bash
# 全テストを実行
pytest tests/ -v

# 特定のテストファイルを実行
pytest tests/test_object_detector.py -v

# カバレッジレポート付きで実行
pytest tests/ --cov=src --cov-report=html
```

または、仮想環境を有効化せずに直接実行:

```bash
./venv/bin/pytest tests/ -v
```

### コードフォーマット

```bash
black src/
```

### 型チェック

```bash
mypy src/
```

## ライセンス

このプロジェクトは個人使用を目的としています。

## サポート

問題が発生した場合は、以下を確認してください:
1. すべての依存関係が正しくインストールされているか
2. macOSの画面収録権限が付与されているか
3. YOLOv8モデルファイルが正しい場所に配置されているか
4. Tesseract OCRが正しくインストールされているか
